# Azure VoiceLive Configuration
# Using AI Foundry resource endpoint (must be in avatar-supported region)
# Avatar regions: Southeast Asia, West US 2, East US 2, West Europe, North Europe, Sweden Central, South Central US
AZURE_VOICELIVE_ENDPOINT=wss://your-ai-foundry-resource.cognitiveservices.azure.com
AZURE_VOICELIVE_API_KEY=your-api-key-here
VOICELIVE_MODEL=gpt-4.1-mini

# Set to true to use Azure DefaultAzureCredential instead of API key
USE_TOKEN_CREDENTIAL=false

# Avatar Configuration
# Video avatars (lisa, max, jenny, guy): require style, no base model, resolution 1280x720
# Photo avatars (Sakura, Matteo, Harry, Meg, Gabrielle): require base model, no style, resolution 512x512
# Custom avatars: set AVATAR_CUSTOMIZED=true, AVATAR_BASE_MODEL=vasa-1, and use your custom avatar name
AVATAR_CHARACTER=Beatriz
AVATAR_STYLE=
AVATAR_CUSTOMIZED=true
AVATAR_BASE_MODEL=vasa-1     # Required for photo/custom avatars (leave empty for video avatars)

# Video Settings
AVATAR_VIDEO_BITRATE=2000000
AVATAR_VIDEO_CODEC=h264

# Voice Settings (use multilingual voice for multi-language support)
# Options: en-US-AvaMultilingualNeural (standard), en-US-Ava:DragonHDLatestNeural (HD quality)
VOICE_NAME=en-US-Ava:DragonHDLatestNeural

# Per-Language Voice Mappings
# Dynamic voice switching uses native voices for each detected language
# See: https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=tts
VOICE_MAPPING_EN=en-US-JennyNeural
VOICE_MAPPING_ZH=zh-CN-XiaoxiaoNeural
VOICE_MAPPING_ZH_HK=zh-HK-HiuMaanNeural
VOICE_MAPPING_MS=ms-MY-YasminNeural
VOICE_MAPPING_TA=ta-IN-PallaviNeural

# Input language detection (comma-separated for multi-language auto-detection)
# Supported language codes:
#   en     - English
#   zh     - Mandarin Chinese
#   zh-HK  - Cantonese (粤语/廣東話)
#   ms     - Malay
#   ta     - Tamil
# Note: Hokkien and Teochew are not supported by Azure Speech Services
INPUT_LANGUAGES=en,zh,zh-HK,ms,ta

# Assistant Instructions (keep responses short for voice interaction)
ASSISTANT_INSTRUCTIONS=You are a helpful AI voice assistant. Keep responses SHORT - maximum 2 sentences. Be concise and conversational.

# Maximum tokens for assistant response
MAX_RESPONSE_TOKENS=100

# Transcription Settings
# Model: whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe, azure-speech
# azure-speech recommended for multilingual (supports Cantonese, phrase lists)
TRANSCRIPTION_MODEL=azure-speech

# Phrase list for domain-specific terms (comma-separated)
# Improves recognition of specific words like project names, acronyms
PHRASE_LIST=Digital Think Tank,DTT,NUHS,Bot-NUHS,Russell-GPT

# VAD (Voice Activity Detection) Tuning
# Adjust these settings if VAD triggers on background noise or misses speech

# VAD threshold (0.0-1.0) - confidence level for speech detection
# Higher = less sensitive (fewer false positives from background noise)
# Lower = more sensitive (may trigger on ambient sounds)
# Recommended: 0.5 (sensitive) to 0.7 (strict) depending on environment
# Set to 0.75 for crowded/noisy environments
VAD_THRESHOLD=0.75

# VAD prefix padding in ms (audio captured before speech starts)
# Increase if first words are being missed
# Decrease if too much background noise is captured before speech
VAD_PREFIX_PADDING_MS=400

# VAD silence duration in ms (how long silence lasts before speech ends)
# Higher = more tolerant of pauses (better for thoughtful speakers)
# Lower = faster response time (may cut off mid-thought)
# Note: Turn-based mode always uses 800ms regardless of this setting
# Set to 1000ms for crowded/noisy environments
VAD_SILENCE_DURATION_MS=1000

# Remove filler words ("um", "uh", "like") from VAD processing
# Helps reduce false triggers in noisy environments
# Recommended: true for noisy environments
VAD_REMOVE_FILLER_WORDS=true

# End-of-Utterance (EOU) Detection Settings
# Controls semantic detection of when user has finished speaking

# EOU threshold level: "low", "medium", "high", "default"
# - low: Faster response, may interrupt mid-thought
# - medium: Balanced (recommended for most environments)
# - high: Waits longer, better for noisy environments
# - default: Uses Azure's default setting
EOU_THRESHOLD_LEVEL=high

# EOU timeout in milliseconds - max time to wait for semantic end detection
# Higher values = more tolerant of pauses, but slower response
# Recommended: 1000ms normal, 1500ms noisy environments
EOU_TIMEOUT_MS=1500

# Noise Reduction Type
# Options: "azure_deep_noise_suppression" (default), "near_field", "far_field"
# azure_deep_noise_suppression: Deep noise suppression (default)
# near_field: Optimized for close-talking microphones (headsets, desk mics)
# far_field: Optimized for distant microphones (room mics, laptop mics in meetings)
NOISE_REDUCTION_TYPE=azure_deep_noise_suppression

# Turn-based mode: When true, VAD doesn't auto-trigger response; response waits for context
# RECOMMENDED: Set to true when using Foundry Agent to ensure RAG context is always available
# In live voice mode (false), responses may start before context retrieval completes
TURN_BASED_MODE=false

# Azure AI Foundry Agent Configuration (for RAG-augmented responses)
# Enable Foundry Agent for knowledge retrieval
FOUNDRY_AGENT_ENABLED=false

# Full AI Foundry project endpoint (required if FOUNDRY_AGENT_ENABLED=true)
# Format: https://<instance>.services.ai.azure.com/api/projects/<project-name>
# Find this in Azure AI Foundry portal > Your Project > Overview
FOUNDRY_ENDPOINT=

# Pre-created agent ID (required if FOUNDRY_AGENT_ENABLED=true)
# Create agent in Azure AI Foundry portal with file_search tool and your knowledge documents
FOUNDRY_AGENT_ID=

# ============================================
# RECOMMENDED SETTINGS FOR NOISY ENVIRONMENTS
# ============================================
# If you experience "conversation_already_has_active_response" errors or
# the system triggers on background noise, try these settings:
#
# VAD_THRESHOLD=0.75               # Less sensitive to noise
# VAD_REMOVE_FILLER_WORDS=true     # Ignore "um", "uh" from noise
# VAD_SILENCE_DURATION_MS=1000     # More tolerant of pauses
# EOU_THRESHOLD_LEVEL=high         # Wait longer before committing
# EOU_TIMEOUT_MS=1500              # More time for semantic detection
# NOISE_REDUCTION_FIELD=near_field # If using headset/close mic
